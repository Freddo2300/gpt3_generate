{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFRbXTHm6U6B"
   },
   "source": [
    "# OpenAI GPT-3 article generation\n",
    "Remember to upload `articles1.csv` and `constants.py` the latter which should include variable `OPENAI_API_KEY` like such:\n",
    "```python\n",
    "OPENAI_API_KEY = \"<your api key>\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T22nL7y97NFm"
   },
   "source": [
    "## Step 1: Handle imports and add .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26536,
     "status": "ok",
     "timestamp": 1652952375707,
     "user": {
      "displayName": "Frederik Strøm Friborg",
      "userId": "08269675509979250915"
     },
     "user_tz": -120
    },
    "id": "mWO-OURKHz5d",
    "outputId": "30662caf-5323-4135-bb15-69bfd0034750"
   },
   "outputs": [],
   "source": [
    "!pip -qqq install openai wandb language-tool-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1859,
     "status": "ok",
     "timestamp": 1652952382368,
     "user": {
      "displayName": "Frederik Strøm Friborg",
      "userId": "08269675509979250915"
     },
     "user_tz": -120
    },
    "id": "0xpnm3WRH6ik",
    "outputId": "b9bdede7-68cc-4d60-8c98-f4e9a1507730"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "import language_tool_python\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "OPENAI_API_KEY = \"YOUR KEY\"\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18550,
     "status": "ok",
     "timestamp": 1652952405606,
     "user": {
      "displayName": "Frederik Strøm Friborg",
      "userId": "08269675509979250915"
     },
     "user_tz": -120
    },
    "id": "9q3DV37HMPJh",
    "outputId": "1285fc70-c6cf-4851-b209-127478720207"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"drive\"): \n",
    "    drive.mount(\"/content/drive\") # The size of our dataset requires a drive mount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1292,
     "status": "ok",
     "timestamp": 1652952412517,
     "user": {
      "displayName": "Frederik Strøm Friborg",
      "userId": "08269675509979250915"
     },
     "user_tz": -120
    },
    "id": "svP5zRxGJ5o3"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"YOUR DRIVE\"): # omit if you don't use drive\n",
    "    csv_path = input() # copy and paste path to articles.csv\n",
    "else:\n",
    "    csv_path = \"YOUR DRIVE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 705,
     "status": "ok",
     "timestamp": 1652952415338,
     "user": {
      "displayName": "Frederik Strøm Friborg",
      "userId": "08269675509979250915"
     },
     "user_tz": -120
    },
    "id": "UTgMBB-uJJei",
    "outputId": "894670c2-9df6-419b-8c31-4444735fc65e"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path, sep=\"\\t\")\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1652952465801,
     "user": {
      "displayName": "Frederik Strøm Friborg",
      "userId": "08269675509979250915"
     },
     "user_tz": -120
    },
    "id": "L1znpNN6d1sf",
    "outputId": "b704ccd9-14bb-4609-cb09-a463f32caec5"
   },
   "outputs": [],
   "source": [
    "print(len(df[\"title\"].value_counts()))\n",
    "print(len(df[\"content\"].value_counts()))\n",
    "\n",
    "print()\n",
    "\n",
    "print(print(df[\"category\"].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gQiArLONt5D"
   },
   "source": [
    "## Step 2: Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 387,
     "status": "ok",
     "timestamp": 1651567514408,
     "user": {
      "displayName": "Frederik Strøm Friborg",
      "userId": "08269675509979250915"
     },
     "user_tz": -120
    },
    "id": "za-h3bdhNpUG",
    "outputId": "633ae979-f5ea-42fa-84a2-72f21b0d3b21"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1183,
     "status": "ok",
     "timestamp": 1652816048683,
     "user": {
      "displayName": "Frederik Strøm Friborg",
      "userId": "08269675509979250915"
     },
     "user_tz": -120
    },
    "id": "zrQl2gEqN8wl",
    "outputId": "0c69349d-8e1c-4d79-d77f-431fa18fee8d"
   },
   "outputs": [],
   "source": [
    "drop_columns = [\"filename\"]\n",
    "if all(item in df.columns for item in drop_columns):\n",
    "    df = df.drop(columns=drop_columns)\n",
    "\n",
    "df = df.drop_duplicates(\"title\")\n",
    "df = df.dropna(subset=[\"content\"])\n",
    "\n",
    "# df[\"year\"] = df[\"year\"].astype(\"int64\")\n",
    "# df[\"year\"] = pd.to_numeric(df[\"year\"], downcast='integer')\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 338,
     "status": "ok",
     "timestamp": 1651567675976,
     "user": {
      "displayName": "Frederik Strøm Friborg",
      "userId": "08269675509979250915"
     },
     "user_tz": -120
    },
    "id": "2qhSIgwBVeTp",
    "outputId": "41194f98-8c96-447b-a693-27a697577eb6"
   },
   "outputs": [],
   "source": [
    "df[\"category\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1651567684265,
     "user": {
      "displayName": "Frederik Strøm Friborg",
      "userId": "08269675509979250915"
     },
     "user_tz": -120
    },
    "id": "efjRKWoX_NlH",
    "outputId": "cf72a8b9-99bc-436c-cda1-db05becf70d5"
   },
   "outputs": [],
   "source": [
    "df[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1_1K8FwPAxq2"
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def regex_title(text):\n",
    "    text = re.sub('(\\s+\\s+)', '', text)\n",
    "    text = re.sub('\\s\\-\\s(((([A-Z][a-z0-9]+)\\s)+[A-Z][a-z0-9]+)|([A-Z][a-z0-9]+))', '', text)\n",
    "    return text.title()\n",
    "\n",
    "def clean_content(text):\n",
    "    text = re.sub('([A-Z]+\\s+\\—+\\s+)|([A-Z]+\\s+[A-Z]+\\s+\\—+\\s+)|([A-Z]+,\\s[A-Z][a-z]+\\s+\\—\\s+)|([A-Z]+,\\s+[A-Z][a-z]+\\s[A-Z][a-z]+\\s+\\—\\s+)', '', text)\n",
    "    text = re.sub('(\\s’s)', '', text)\n",
    "    text = re.sub('’(\\s+’+)+\\s+', '', text)\n",
    "    text = re.sub('(\\s+\\s+)', ' ', text)\n",
    "    text = re.sub('’{2}', '’', text)\n",
    "    text = re.sub('((’t)+)', '', text)\n",
    "    text = re.sub(\"\\\\\\\\\", \"\", text)\n",
    "    text = re.sub('\\A\\s', '', text)\n",
    "    text = re.sub('\\s$', '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def grammar_score(text, tool):\n",
    "    error_count = 0\n",
    "    for sentence in text_to_sentences(text):\n",
    "        check = tool.check(sentence)\n",
    "        sentence_errors = len(check)\n",
    "        error_count += sentence_errors\n",
    "    \n",
    "    word_count = re.split('\\s+', text)\n",
    "    word_count = len([tok for tok in word_count if tok not in stop_words])\n",
    "\n",
    "    error_score = 1 - (float(error_count) / float(word_count))\n",
    "\n",
    "    return error_score\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def regex_content(text):\n",
    "    text = re.sub('http\\S+', ' ', text)\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    return text.lower()\n",
    "\n",
    "\"\"\"\n",
    "def clean_text(text):\n",
    "    text = re.sub('(\\s\\(CNN\\)\\s)', '', text)\n",
    "    text = re.sub('(\\sREAD:.*)', '', text)\n",
    "    text = re.sub('(\\.\\s\\.\\.)', '...', text)\n",
    "    text = re.sub('(.\\”\\s’)', '”', text)\n",
    "    text = re.sub('(\\s’\\s)', ' ', text)\n",
    "    return text\n",
    "\"\"\"\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = re.split('\\s+', text)\n",
    "    tokens = [tok for tok in tokens if tok not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "def lemmatize(tokens):\n",
    "    lemms = [lemmatizer.lemmatize(tok) for tok in tokens]\n",
    "    return lemms\n",
    "\n",
    "def text_to_sentences(text):\n",
    "    assert type(text) == type(\"\") or type(text) == np.str_\n",
    "    return re.split(\"[\\.\\?\\!]\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "llZYf4USGluB"
   },
   "outputs": [],
   "source": [
    "df[\"title\"] = df['title'].apply(lambda x: regex_title(x))\n",
    "# df[\"title\"] = df[\"title\"].apply(lambda x: re.sub('(’S)', '’s', x))\n",
    "df[\"content\"] = df[\"content\"].apply(lambda x: clean_content(x))\n",
    "# df[\"content\"] = df[\"content\"].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "executionInfo": {
     "elapsed": 262,
     "status": "ok",
     "timestamp": 1651569731197,
     "user": {
      "displayName": "Frederik Strøm Friborg",
      "userId": "08269675509979250915"
     },
     "user_tz": -120
    },
    "id": "Y8_yfs1EHM3I",
    "outputId": "2aee2f3b-0ec1-4bf8-8405-792b18ff7d12"
   },
   "outputs": [],
   "source": [
    "df[\"content\"][200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UhysmF4smvDX"
   },
   "outputs": [],
   "source": [
    "df['regexed'] = df['content'].apply(lambda x: regex_content(x))\n",
    "df['tokens'] = df['regexed'].apply(lambda x: tokenize(x))\n",
    "df[\"lemmas\"] = df[\"tokens\"].apply(lambda x: lemmatize(x))\n",
    "df['word_count'] = df['tokens'].apply(lambda x: len(x))\n",
    "df['title_len'] = df['title'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "te92r3fbOY6D"
   },
   "outputs": [],
   "source": [
    "df = df[df['word_count'] > 200]\n",
    "df = df[df['word_count'] <= 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1651569798626,
     "user": {
      "displayName": "Frederik Strøm Friborg",
      "userId": "08269675509979250915"
     },
     "user_tz": -120
    },
    "id": "7l5MSI8zPMhH",
    "outputId": "b5f3a9de-d895-4ab2-a62e-93247a2f9032"
   },
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ol-lHyYxOVfQ"
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"YOUR PATH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06Mid6c7obVN"
   },
   "source": [
    "## Step 3: Partition pre-processed data into GPT-3 vs classifier data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1530,
     "status": "ok",
     "timestamp": 1652815794258,
     "user": {
      "displayName": "Frederik Strøm Friborg",
      "userId": "08269675509979250915"
     },
     "user_tz": -120
    },
    "id": "O4Vw-Pg8tC8S",
    "outputId": "fd7e605c-657a-433c-d3e4-623499e3b830"
   },
   "outputs": [],
   "source": [
    "p = \"YOUR PATH\"\n",
    "df = pd.read_csv(p)\n",
    "df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1652815796935,
     "user": {
      "displayName": "Frederik Strøm Friborg",
      "userId": "08269675509979250915"
     },
     "user_tz": -120
    },
    "id": "rRETjJ98Oj7I",
    "outputId": "9a381987-e026-42ba-e462-445f9a9e1d10"
   },
   "outputs": [],
   "source": [
    "df[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-yL0H_KaDxY7"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def clear_sample(text):\n",
    "    for sentence in text_to_sentences(text):\n",
    "        sentence = re.sub('”\\s', '', sentence)\n",
    "        sentence = re.sub('\\A\\s”', '', sentence)\n",
    "        sentence = re.sub('\\A””\\s', '', sentence)\n",
    "        sentence = re.sub('\\A”’', '', sentence)\n",
    "        sentence = re.sub('\\A’\\s', '', sentence)\n",
    "        sentence = re.sub('\\A\\s', '', sentence)\n",
    "        sentence = re.sub('\\A’', '', sentence)\n",
    "        sentence = re.sub('\\A”', '', sentence)\n",
    "        sentence = re.sub('\\A\\t', '', sentence)\n",
    "        sentence += \".\"\n",
    "        sentence = re.sub('\\A\\.', '', sentence)\n",
    "    return text\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "df_total = df.groupby('category', group_keys=False).apply(lambda x: x.sample(min(len(x), 72)))\n",
    "df_total = df_total.reset_index(drop=True)\n",
    "\n",
    "#df_total[\"content\"] = df_total[\"content\"].apply(lambda x: clear_sample(x))\n",
    "\n",
    "df_gpt3 = df_total.groupby('category', group_keys=False).apply(lambda x: x.sample(min(len(x), 30)))     # This is for fine-tuning + training classifier\n",
    "df_class = df_total[~df_total.isin(df_gpt3)].dropna(how = 'all')                                        # Partition into two seperate below\n",
    "headlines = df_class.groupby('category', group_keys=False).apply(lambda x: x.sample(min(len(x), 36)))   # headlines is for testing classifier + testing human + training classifier\n",
    "last_30 = df_class[~df_class.isin(headlines)].dropna(how = 'all')                                       # holdout data                               \n",
    "\n",
    "df_gpt3 = df_gpt3.reset_index(drop=True)\n",
    "df_class = df_class.reset_index(drop=True)\n",
    "\n",
    "prompt_completion = df_gpt3\n",
    "\n",
    "prompt_completion = prompt_completion.drop(columns=[\"category\", \"regexed\", \"tokens\", \"lemmas\", \"word_count\", \"title_len\"])\n",
    "prompt_completion = prompt_completion.rename(columns={\"title\": \"prompt\", \"content\": \"completion\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 400,
     "status": "ok",
     "timestamp": 1651594616021,
     "user": {
      "displayName": "Frederik Strøm Friborg",
      "userId": "08269675509979250915"
     },
     "user_tz": -120
    },
    "id": "VzCPHc15PiV3",
    "outputId": "8545f0b3-b86a-4d9a-afc9-af8120117da7"
   },
   "outputs": [],
   "source": [
    "len(df_gpt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D2MDswhKSmY9"
   },
   "outputs": [],
   "source": [
    "df_gpt3.to_csv(\"YOUR PATH\", index=False)\n",
    "headlines.to_csv(\"YOUR PATH\")\n",
    "prompt_completion.to_csv(\"YOUR PATH\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VlAmfw1G7ykQ"
   },
   "source": [
    "## Step 4: Prepare fine-tuned OpenAI model using prompt-completion keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P7HiTIaHSJRA"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"YOUR PATH\"):\n",
    "    path = input() # Insert path to new cleaned .csv file\n",
    "else:\n",
    "    path = \"YOUR PATH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 272,
     "status": "ok",
     "timestamp": 1651484738972,
     "user": {
      "displayName": "Frederik Strøm Friborg",
      "userId": "08269675509979250915"
     },
     "user_tz": -120
    },
    "id": "mPpJTzRVS1dc",
    "outputId": "5a1d12aa-c72f-4149-ebba-d26d09cb8cd4"
   },
   "outputs": [],
   "source": [
    "df_gpt3 = pd.read_csv(path)\n",
    "# df_gpt3 = df_gpt3.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "len(df_gpt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13439,
     "status": "ok",
     "timestamp": 1651589667484,
     "user": {
      "displayName": "Frederik Strøm Friborg",
      "userId": "08269675509979250915"
     },
     "user_tz": -120
    },
    "id": "Yvef-6kRys9N",
    "outputId": "99f02053-46af-4092-8656-545b114c9f36"
   },
   "outputs": [],
   "source": [
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "!openai tools fine_tunes.prepare_data -f \"YOUR PATH\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8ZiTcrUptY_"
   },
   "source": [
    "## Step 5: Generate articles using GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 674,
     "status": "ok",
     "timestamp": 1651595750601,
     "user": {
      "displayName": "Frederik Strøm Friborg",
      "userId": "08269675509979250915"
     },
     "user_tz": -120
    },
    "id": "TB6O8XriqKWb",
    "outputId": "0c8bcd54-85d4-4840-853b-23ae629e7dff"
   },
   "outputs": [],
   "source": [
    "openai.api_key = OPENAI_API_KEY\n",
    "openai.organization = \"YOUR ORGANIZATION\"\n",
    "\n",
    "openai.FineTune.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 304,
     "status": "ok",
     "timestamp": 1651594874226,
     "user": {
      "displayName": "Frederik Strøm Friborg",
      "userId": "08269675509979250915"
     },
     "user_tz": -120
    },
    "id": "4LQy25LScreg",
    "outputId": "a67c8221-1a22-40b8-e167-da2974c760f5"
   },
   "outputs": [],
   "source": [
    "headlines = pd.read_csv(\"YOUR PATH\")\n",
    "headlines = headlines.drop(columns=[\"Unnamed: 0\"])\n",
    "headlines = headlines.reset_index(drop=True)\n",
    "headlines = headlines.drop(columns=[\"regexed\", \"tokens\", \"lemmas\", \"word_count\", \"title_len\"])\n",
    "headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4APYUB4fIL4R"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def call_gpt3(headline):\n",
    "    prompt = headline+\" ->\"\n",
    "    response_full = openai.Completion.create(model='YOUR MODEL', prompt=prompt, stop=[\"\\n\"], max_tokens=300, n=1, temperature=0.7, frequency_penalty=0.2)\n",
    "    response = response_full.get('choices')[0].text.strip()\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lLPv9-_8IUji"
   },
   "outputs": [],
   "source": [
    "gpt3_outputs = pd.DataFrame(outputs, columns=[\"gpt3\"])\n",
    "gpt3_outputs.to_csv(\"YOUR DRIVE\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 266,
     "status": "ok",
     "timestamp": 1651602802931,
     "user": {
      "displayName": "Frederik Strøm Friborg",
      "userId": "08269675509979250915"
     },
     "user_tz": -120
    },
    "id": "pZKtrCQd99Rh",
    "outputId": "78521622-f870-4653-94e3-ce1541a82a31"
   },
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "executionInfo": {
     "elapsed": 352,
     "status": "ok",
     "timestamp": 1651602845145,
     "user": {
      "displayName": "Frederik Strøm Friborg",
      "userId": "08269675509979250915"
     },
     "user_tz": -120
    },
    "id": "tgD9J6QsDi2k",
    "outputId": "0f29fe09-8c17-416a-a049-40527f47fc40"
   },
   "outputs": [],
   "source": [
    "rest = pd.DataFrame(outputs, columns=[\"gpt3\"])\n",
    "rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zVrvm40vM6Si"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "combined = gpt3_outputs.append(rest)\n",
    "combined = combined.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 293,
     "status": "ok",
     "timestamp": 1651603603764,
     "user": {
      "displayName": "Frederik Strøm Friborg",
      "userId": "08269675509979250915"
     },
     "user_tz": -120
    },
    "id": "YZ9ZMjvjNV_G",
    "outputId": "ba0b8d36-2f13-45f2-cf8a-6012a1e83ccb"
   },
   "outputs": [],
   "source": [
    "headlines[\"gpt3\"] = combined[\"gpt3\"]\n",
    "headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7XxMSNZ8P2i4"
   },
   "outputs": [],
   "source": [
    "headlines.to_csv(\"YOUR PATH\", index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "generate_gpt3_articles.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
